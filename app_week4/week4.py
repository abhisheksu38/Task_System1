# -*- coding: utf-8 -*-
"""week4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1busBtKyykdmPxp19ZDkXRKTePZeaiqtS
"""

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.metrics import classification_report
import joblib
import streamlit as st

uploaded_file = st.file_uploader("Upload your CSV file", type=["csv"])

if uploaded_file is not None:
    df = pd.read_csv(uploaded_file)
    st.write("Uploaded Data Preview:")
    st.dataframe(df.head())

    # Continue with predictions here...

# Fill missing values
df['Income'] = df['Income'].fillna(df['Income'].mean())

# Simulate Task Classification and Priority (if not present)
df['Task_Category'] = np.random.choice(['email', 'call', 'survey'], len(df))
df['Priority'] = np.random.choice(['low', 'medium', 'high'], len(df))

# Label encode target variables
le_task = LabelEncoder()
df['Task_Category_encoded'] = le_task.fit_transform(df['Task_Category'])

le_priority = LabelEncoder()
df['Priority_encoded'] = le_priority.fit_transform(df['Priority'])

# Feature selection (you can adjust this list)
features = ['Age', 'Income', 'Recency', 'Kidhome', 'Teenhome', 'Family_Size']
df = df.dropna(subset=features)  # Drop if required fields are missing
X = df[features]

# Scale features
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Save the scaler
joblib.dump(scaler, 'scaler.pkl')

# Define task classification target
y_task = df['Task_Category_encoded']

# Split and train
X_task_train, X_task_test, y_task_train, y_task_test = train_test_split(X_scaled, y_task, test_size=0.2, random_state=42)

task_model = RandomForestClassifier(n_estimators=100, random_state=42)
task_model.fit(X_task_train, y_task_train)

# Evaluate
y_task_pred = task_model.predict(X_task_test)
print("Task Classification Report:\n", classification_report(y_task_test, y_task_pred))

# Save model
joblib.dump(task_model, 'final_task_classifier.pkl')

# Define priority prediction target
y_priority = df['Priority_encoded']

# Split and train
X_pri_train, X_pri_test, y_pri_train, y_pri_test = train_test_split(X_scaled, y_priority, test_size=0.2, random_state=42)

priority_model = XGBClassifier(random_state=42, eval_metric='mlogloss')
priority_model.fit(X_pri_train, y_pri_train)

# Evaluate
y_pri_pred = priority_model.predict(X_pri_test)
print("Priority Prediction Report:\n", classification_report(y_pri_test, y_pri_pred))

# Save model
joblib.dump(priority_model, 'final_priority_predictor.pkl')

"""## Dashboard mockup or output summary"""

import streamlit as st
import pandas as pd

# Create model summary dataframe
summary = pd.DataFrame({
    'Model': ['Task Classifier', 'Priority Predictor'],
    'Algorithm': ['Random Forest', 'XGBoost'],
    'Accuracy': [round(task_model.score(X_task_test, y_task_test), 4),
                 round(priority_model.score(X_pri_test, y_pri_test), 4)],
    'Saved Model File': ['final_task_classifier.pkl', 'final_priority_predictor.pkl']
})

# Show on Streamlit app
st.subheader("Model Summary")
st.dataframe(summary)

# Option to download the summary as CSV
csv = summary.to_csv(index=False).encode('utf-8')
st.download_button("Download Model Summary CSV", data=csv, file_name="model_summary.csv", mime='text/csv')

# app.py
import streamlit as st
import pandas as pd
import joblib

st.title("Task Predictor")

# Load models and scaler
@st.cache_resource
def load_models():
    task_model = joblib.load("final_task_classifier.pkl")
    priority_model = joblib.load("final_priority_predictor.pkl")
    scaler = joblib.load("scaler.pkl")
    return task_model, priority_model, scaler

task_model, priority_model, scaler = load_models()

st.set_page_config(page_title="Task Assignment Dashboard", layout="wide")
st.title("üß† Task Classification & Priority Prediction")

uploaded_file = st.file_uploader("üì§ Upload your task dataset (.csv)", type=["csv"])

if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.subheader("üîç Input Data Preview")
    st.dataframe(df.head())

    # Required input features
    required_cols = ['Age', 'Income', 'Recency', 'Kidhome', 'Teenhome', 'Family_Size']
    missing_cols = [col for col in required_cols if col not in df.columns]

    if missing_cols:
        st.error(f"‚ùå Missing columns: {missing_cols}")
    else:
        # Fill missing values if any
        df[required_cols] = df[required_cols].fillna(df[required_cols].mean())

        # Scale features
        X = scaler.transform(df[required_cols])

        # Predictions
        task_pred = task_model.predict(X)
        priority_pred = priority_model.predict(X)

        # Add to output
        df['Predicted_Task_Category'] = task_pred
        df['Predicted_Priority'] = priority_pred

        st.success("‚úÖ Predictions complete!")
        st.subheader("üìä Prediction Output")
        st.dataframe(df[['Predicted_Task_Category', 'Predicted_Priority']].head())

        # Option to download
        csv = df.to_csv(index=False).encode('utf-8')
        st.download_button("‚¨áÔ∏è Download Full Result CSV", data=csv, file_name='predictions_output.csv', mime='text/csv')